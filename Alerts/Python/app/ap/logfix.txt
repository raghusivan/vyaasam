from config_handler import ConfigHandler
from url_builder import UrlBuilder
from http_client import HttpClient
from logger_config import setup_logger, LoggerManager
from datetime import datetime
import sys
import json
import os

class AlertProcessor:
    def __init__(self, config_path: str = 'config.ini'):
        """Initialize configuration, logger, and components."""
        # Load config
        config_handler = ConfigHandler()
        self.config = config_handler.load_config(config_path)

        # Initialize logger with dynamic debug level
        debug_enabled = self.config['settings'].get('debug_enabled', 'false').lower() == 'true'
        log_level = 'DEBUG' if debug_enabled else 'INFO'
        self.logger = setup_logger('AlertProcessor', log_level)
        
        LoggerManager.log_section(self.logger, "ALERT PROCESSOR INITIALIZATION")

        # Log configuration info
        self.logger.info(f"Configuration loaded from: {config_path}")
        self.logger.info(f"Debugging Enabled: {debug_enabled}")

        # Initialize components
        self.url_builder = UrlBuilder(self.config['settings']['url'])
        self.http_client = HttpClient(
            self.config['authentication']['username'],
            self.config['authentication']['password']
        )

        # Read is_resolved filter
        self.is_resolved_filter = self.config['settings'].get('is_resolved', 'all').lower()
        self.logger.debug(f"Filter for 'is_resolved': {self.is_resolved_filter}")
        
        # Set output file name with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_file = f"filtered_alerts_{timestamp}.json"
        self.logger.info(f"Output file will be named: {self.output_file}")

        # Initialize output file
        self.create_or_clear_output_file()
        self.logger.info("Initialization complete.")

    def create_or_clear_output_file(self):
        """Create or clear the output file at the start of processing."""
        with open(self.output_file, 'w') as file:
            json.dump({"messages": [], "total_messages": 0}, file, indent=2)  # Initialize JSON structure
        self.logger.info(f"Output file '{self.output_file}' initialized.")

    def process_status(self, status_key: str, status_value: str) -> dict:
        """Process a single status and extract individual messages."""
        LoggerManager.log_section(self.logger, f"Processing Status: {status_key}")
        try:
            # Build the URL
            self.logger.debug(f"Building URL for status '{status_key}'...")
            url = self.url_builder.build_url(
                self.config['settings']['start_datetime'],
                int(self.config['settings']['days_to_retrieve']),
                status_value
            )
            self.logger.debug(f"URL built: {url}")

            # Get response data
            self.logger.info("Fetching alerts from the server...")
            response_data = self.http_client.get(url)
            self.logger.debug(f"Raw server response: {json.dumps(response_data, indent=2)}")

            # Verify messages exist and extract
            if 'messages' in response_data and isinstance(response_data['messages'], list):
                top_level_messages = response_data['messages']
                self.logger.info(f"Top-level messages count: {len(top_level_messages)}")

                # Extract and filter messages wrapped in {}
                filtered_messages = self.extract_and_filter_messages(top_level_messages)
                self.logger.info(f"Filtered individual messages count: {len(filtered_messages)}")

                # Append filtered messages to the single output file
                self.append_messages_to_file(filtered_messages)

                return {
                    'status': status_key,
                    'total': len(top_level_messages),
                    'filtered': len(filtered_messages),
                    'success': True
                }

            self.logger.warning(f"No 'messages' field found in response for status '{status_key}'.")
            return {
                'status': status_key,
                'total': 0,
                'filtered': 0,
                'success': False
            }

        except Exception as e:
            self.logger.error(f"Failed to process status '{status_key}': {str(e)}", exc_info=True)
            return {
                'status': status_key,
                'error': str(e),
                'success': False
            }

    def extract_and_filter_messages(self, top_level_messages: list) -> list:
        """Extract and filter individual messages from the top-level 'messages'."""
        filtered_messages = []
        for top_message in top_level_messages:
            # Log the message being inspected
            self.logger.debug(f"Inspecting message: {top_message.get('message_id')}")
            if isinstance(top_message, dict) and self.should_include_message(top_message):
                filtered_messages.append(top_message)
        return filtered_messages

    def should_include_message(self, message: dict) -> bool:
        """Check if a message matches the 'is_resolved' filter."""
        if self.is_resolved_filter == 'true':
            return message.get('is_resolved') is True
        elif self.is_resolved_filter == 'false':
            return message.get('is_resolved') is False
        return True  # 'all' case

    def append_messages_to_file(self, messages: list):
        """Append filtered messages to the output JSON file."""
        if not messages:
            self.logger.info("No messages to append.")
            return

        # Load existing data
        with open(self.output_file, 'r+') as file:
            data = json.load(file)
            data['messages'].extend(messages)  # Append new messages
            data['total_messages'] = len(data['messages'])  # Update total count
            file.seek(0)
            json.dump(data, file, indent=2)

        self.logger.info(f"Appended {len(messages)} messages to '{self.output_file}'.")

    def run(self) -> dict:
        """Main execution method."""
        LoggerManager.log_section(self.logger, "STARTING ALERT PROCESSING")
        start_time = datetime.now()

        results = {
            'processed': 0,
            'successful': 0,
            'failed': 0,
            'details': []
        }

        try:
            for status_key, status_value in self.config['statuses'].items():
                self.logger.info(f"Processing status: {status_key}")
                result = self.process_status(status_key, status_value)

                if result['success']:
                    results['successful'] += 1
                else:
                    results['failed'] += 1

                results['processed'] += 1
                results['details'].append(result)

        except Exception as e:
            self.logger.error(f"Unexpected error during processing: {str(e)}", exc_info=True)

        finally:
            duration = (datetime.now() - start_time).total_seconds()
            results['duration'] = duration

            LoggerManager.log_section(self.logger, "PROCESSING COMPLETE")
            self.logger.info(f"Total Processed: {results['processed']}")
            self.logger.info(f"Successful: {results['successful']}")
            self.logger.info(f"Failed: {results['failed']}")
            self.logger.info(f"Duration: {duration:.2f} seconds")

        return results


def main():
    """Main method to execute the alert processor."""
    logger = setup_logger('Main', 'INFO')
    try:
        logger.info("Starting Alert Processor...")
        processor = AlertProcessor()
        processor.run()
        logger.info("Processing completed successfully.")
        sys.exit(0)

    except Exception as e:
        logger.error(f"Critical error: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
